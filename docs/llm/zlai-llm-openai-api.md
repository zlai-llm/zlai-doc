# å¼€æºå¤§æ¨¡å‹éƒ¨ç½²

> ZLAIåœ¨ç‰ˆæœ¬(0.3.104+)åä¼šé™†ç»­æ”¯æŒæœ¬åœ°åŒ–éƒ¨ç½²å¼€æºå¤§æ¨¡å‹ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºChatGLMã€Qwenã€LLaMAã€Baichuanç­‰ï¼Œå¹¶ä»¥`OpenAI`çš„æ¥å£å½¢å¼æä¾›ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿæ¥å…¥å’Œä½¿ç”¨ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ”¯æŒå¿«é€Ÿä¸ZLAIçš„å…¶å®ƒåŠŸèƒ½è¿›è¡Œæ•´åˆï¼Œä¾‹å¦‚`ZLAI`çš„`Embedding`ã€`Agent`ã€`Prompt`ã€`LLM`ã€`Chat`ç­‰ã€‚

## å·²ç»é€šè¿‡æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨

> [![Python package](https://img.shields.io/pypi/v/zlai)](https://pypi.org/project/zlai/)æ”¯æŒéƒ¨ç½²ä»¥ä¸‹æ¨¡å‹ï¼ˆ[å¯¹è¯](llm/zlai-llm-openai-api?id=chat-completion)ã€[Function Call](llm/zlai-llm-openai-api?id=function-call)ã€[å¤šæ¨¡æ€](llm/zlai-llm-openai-api?id=å¤šæ¨¡æ€æ¨¡å‹)ã€[æ–‡ç”Ÿå›¾](llm/zlai-llm-openai-api?id=image-generate)ã€[å›¾ç”Ÿå›¾](llm/zlai-llm-openai-api?id=image-edit)ã€[æ–‡å­—è½¬è¯­éŸ³`TTS`](llm/zlai-llm-openai-api?id=audio)ã€[Embedding](llm/zlai-llm-openai-api?id=embedding)ï¼‰ï¼Œå¹¶ä¸”å·²ç»é€šè¿‡`OpenAI-SDK`æµ‹è¯•ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚

| ç±»å‹         | ç³»åˆ—        | æ¨¡å‹                                                                                                 | æ™®é€šæ¨ç† | æµå¼æ¨ç† | FunctionCall |
|------------|-----------|----------------------------------------------------------------------------------------------------|------|------|--------------|
| å¯¹è¯         | Qwen2     | [Qwen2-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2-0.5B-Instruct)                             | âœ”ï¸   | âœ”ï¸   | æš‚ä¸æ”¯æŒ         |
| å¯¹è¯         | Qwen2     | [Qwen2-1.5B-Instruct](https://huggingface.co/Qwen/Qwen2-1.5B-Instruct)                             | âœ”ï¸   | âœ”ï¸   | æš‚ä¸æ”¯æŒ         |
| å¯¹è¯         | Qwen2     | [Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct)                                 | âœ”ï¸   | âœ”ï¸   | æš‚ä¸æ”¯æŒ         |
| å¯¹è¯         | Qwen2     | [Qwen2-57B-A14B-Instruct-GPTQ-Int4](https://huggingface.co/Qwen/Qwen2-57B-A14B-Instruct-GPTQ-Int4) | âœ”ï¸   | âœ”ï¸   | æš‚ä¸æ”¯æŒ         |
| å¯¹è¯         | GLM4      | [glm-4-9b-chat](https://huggingface.co/THUDM/glm-4-9b-chat)                                        | âœ”ï¸   | âœ”ï¸   | âœ”ï¸           |
| å¯¹è¯         | GLM4      | [glm-4-9b-chat-1m](https://huggingface.co/THUDM/glm-4-9b-chat-1m)                                  | âœ”ï¸   | âœ”ï¸   | âœ”ï¸           |
| å¤šæ¨¡æ€        | GLM4      | [glm-4v-9b](https://huggingface.co/THUDM/glm-4v-9b)                                                | âœ”ï¸   | âœ”ï¸   | âœ”ï¸           |
| å¤šæ¨¡æ€        | MiniCPM   | [MiniCPM-V-2_6](https://huggingface.co/openbmb/MiniCPM-V-2_6)                                      | âœ”ï¸   | âœ”ï¸   | âœ”ï¸           |
| æ–‡ç”Ÿå›¾        | Kolors    | [Kolors-diffusers](https://huggingface.co/Kwai-Kolors/Kolors-diffusers)                            | âœ”ï¸   | âŒ    | âŒ            |
| å›¾ç”Ÿå›¾        | Kolors    | [Kolors-image2image](https://huggingface.co/Kwai-Kolors/Kolors-diffusers)                          | âœ”ï¸   | âŒ    | âŒ            |
| æ–‡å­—è½¬è¯­éŸ³`TTS` | CosyVoice | [CosyVoice-300M](https://huggingface.co/FunAudioLLM/CosyVoice-300M)                                | âœ”ï¸   | âŒ    | âŒ            |
| Embedding  | BGE       | [bge-m3](https://huggingface.co/BAAI/bge-m3)                                                       | âœ”ï¸   | âŒ    | âŒ            |

## éƒ¨ç½²æ–¹å¼

> éƒ¨ç½²æ–¹å¼

```bash
# æ›´æ–° ZLAI Package
pip install zlai["local"] -U

# å¯åŠ¨æœ¬åœ°åŒ–éƒ¨ç½²
zlai_models --config_path "./models_config.yml" --reload=0 --port=8000 --host "0.0.0.0"
```

> éƒ¨ç½²å‚æ•°

- `config_path`: æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé…ç½®æ–‡ä»¶[å‚è€ƒ](https://github.com/zlai-llm/zlai/blob/master/models_config.yml)
- `reload`: åœ¨ä»£ç æˆ–æ–‡ä»¶æ›´æ–°åAPIæ˜¯å¦çƒ­æ›´æ–°ï¼Œé»˜è®¤ä¸º`0`ï¼Œä¸è‡ªåŠ¨åŠ è½½æ›´æ–°
- `port`: APIæœåŠ¡ç«¯å£ï¼Œé»˜è®¤ä¸º`8000`
- `host`: APIæœåŠ¡åœ°å€ï¼Œé»˜è®¤ä¸º`localhost`ï¼ŒæŒ‡å®šä¸º`0.0.0.0`åå¯ä»¥é€šè¿‡`IP`è®¿é—®

> [é…ç½®æ–‡ä»¶è¯´æ˜](https://github.com/zlai-llm/zlai/blob/master/models_config.yml)

```yaml
models_config:
  - model_name: Qwen2-0.5B-Instruct                      # æ¨¡å‹åç§°
    model_path: /home/models/Qwen/Qwen2-0.5B-Instruct    # æ¨¡å‹æ–‡ä»¶è·¯å¾„
    model_type: completion                               # æ¨¡å‹ç±»å‹ï¼Œç›®å‰æ”¯æŒ`completion`ã€`embedding`
    load_method: load_qwen2                              # åŠ è½½æ¨¡å‹æ–¹æ³•ï¼Œç›®å‰æ”¯æŒ`load_qwen2`ã€`load_glm4`
    max_memory:                                          # æ¨¡å‹æœ€å¤§æ˜¾å­˜
      0: "2GB"
  - model_name: Qwen2-1.5B-Instruct
    model_path: /home/models/Qwen/Qwen2-1.5B-Instruct
    model_type: completion
    load_method: load_qwen2
    max_memory:
      0: "4GB"
```

## API-Doc

> [http://localhost:8000/docs](http://localhost:8000/docs)

<center>
<img src="img/llm/zlai-llm-openai-api-doc.png" width="100%">
</center>

## Model List

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
models_list = client.models.list()
print(models_list.data)
```

*è¾“å‡º*

```text
[Model(id='Qwen2-0.5B-Instruct', created=None, object='model', owned_by='Open Source'),
 Model(id='Qwen2-1.5B-Instruct', created=None, object='model', owned_by='Open Source'),
 Model(id='Qwen2-7B-Instruct', created=None, object='model', owned_by='Open Source'),
 Model(id='Qwen2-57B-A14B-Instruct-GPTQ-Int4', created=None, object='model', owned_by='Open Source'),
 Model(id='glm-4-9b-chat', created=None, object='model', owned_by='Open Source'),
 Model(id='glm-4-9b-chat-1m', created=None, object='model', owned_by='Open Source'),
 Model(id='glm-4v-9b', created=None, object='model', owned_by='Open Source'),
 Model(id='bge-m3', created=None, object='model', owned_by='Open Source'),
 Model(id='kolors-diffusers', created=None, object='model', owned_by='Open Source'),
 Model(id='mini_cpm-v2_6', created=None, object='model', owned_by='Open Source')]
```

## Chat Completion

> é€šç”¨é—®ç­”æ¥å£ç¤ºä¾‹

### Chat Completion

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
completion = client.chat.completions.create(
    model="glm-4-9b-chat",
    messages=[
        {"role": "user", "content": "ä½ å¥½"},
    ],
    stream=False
)
print(completion.choices[0].message.content)
```

*è¾“å‡º*

```text
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
```

### Stream Chat Completion

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
completion = client.chat.completions.create(
    model="glm-4-9b-chat",
    messages=[
        {"role": "user", "content": "ä½ å¥½"},
    ],
    stream=True
)

for chunk in completion:
    content = chunk.choices[0].delta.content
    print(content, flush=True, end='')
```

*è¾“å‡º*

```text
ä½ å¥½
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ 
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆ
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ 
```

## Function Call

> å·¥å…·è°ƒç”¨æ¥å£ç¤ºä¾‹

> tools example

```python
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "Get the current weather",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    },
                    "format": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "The temperature unit to use. Infer this from the users location.",
                    },
                },
                "required": ["location", "format"],
            },
        }
    },
]
```

### Normal Function Call

#### Function Call

> code

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
completion = client.chat.completions.create(
    model="glm-4-9b-chat",
    messages=[
        {"role": "user", "content": "What's the Celsius temperature in San Francisco?"},
    ],
    tools=tools,
    tool_choice="auto",
    stream=False,
)
print(completion.choices[0].message.tool_calls[0].function.name)
print(completion.choices[0].message.tool_calls[0].function.arguments)
```

*è¾“å‡º*

```text
get_current_weather

{"location": "San Francisco, CA", "format": "celsius"}
```

#### Call Function

```python
from zlai.types.messages import ToolMessage

messages=[
    UserMessage(content="What's the Celsius temperature in San Francisco?"),
    completion.choices[0].message,
    ToolMessage(content="{San Francisco, CA: {celsius: 15}}"),
]

completion = client.chat.completions.create(
    model="glm-4-9b-chat", messages=messages,
    tools=tools, tool_choice="auto", stream=False,
)
```

*è¾“å‡º*

```text
The current Celsius temperature in San Francisco is 15 degrees.
```

### Stream Function Call

#### Function Call

> code

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
completion = client.chat.completions.create(
    model="glm-4-9b-chat",
    messages=[
        {"role": "user", "content": "What's the Celsius temperature in San Francisco?"},
    ],
    tools=tools,
    tool_choice="auto",
    stream=True,
)

answer = ""
for chunk in completion:
    content = chunk.choices[0].delta.content
    if content:
        answer += content
        print(answer)
```

*è¾“å‡º*

```text
 get_current_weather

 get_current_weather
{"location": 
 get_current_weather
{"location": "San 
 get_current_weather
{"location": "San Francisco, 
 get_current_weather
{"location": "San Francisco, CA", 
 get_current_weather
{"location": "San Francisco, CA", "format": 
 get_current_weather
{"location": "San Francisco, CA", "format": "celsius"} 
```

> Function Call Parameters

```python
print("content: ", chunk.choices[0].delta.content)
if chunk.choices[0].delta.tool_calls:
    print("function name: ", chunk.choices[0].delta.tool_calls[0].function.name)
    print("function arguments: ", chunk.choices[0].delta.tool_calls[0].function.arguments)
```

*è¾“å‡º*

```text
content:  None
function name:  get_current_weather
function arguments:  {"location": "San Francisco, CA", "format": "celsius"}
```

#### Call Function

```python
from zlai.types.messages import ToolMessage

messages=[
    UserMessage(content="What's the Celsius temperature in San Francisco?"),
    completion.choices[0].message,
    ToolMessage(content="{San Francisco, CA: {celsius: 15}}"),
]

completion = client.chat.completions.create(
    model="glm-4-9b-chat", messages=messages, tools=tools, 
    tool_choice="auto", stream=True, 
)

answer = ""
for chunk in completion:
    content = chunk.choices[0].delta.content
    if content:
        answer += content
        print(answer)
```

*è¾“å‡º*

```text
The 
The current 
The current Celsius 
The current Celsius temperature 
The current Celsius temperature in 
The current Celsius temperature in San 
The current Celsius temperature in San Francisco 
The current Celsius temperature in San Francisco is 
The current Celsius temperature in San Francisco is 15  
The current Celsius temperature in San Francisco is 15 degrees. 
```

## å¤šæ¨¡æ€æ¨¡å‹

**Example**: `glm-4v-9b`
**Image**: [Image](https://pic2.zhimg.com/v2-70ea697c0edec518b9d513a49228e489_b.jpg)

### Chat Completion

```python
from openai import OpenAI
from zlai.types.messages import ImageMessage, UserMessage, AssistantMessage

url = "https://pic2.zhimg.com/v2-70ea697c0edec518b9d513a49228e489_b.jpg"
messages = [
    ImageMessage(content="è§£æå›¾ç‰‡ä¸­çš„æ–‡å­—", images_url=[url]),
]
messages = [message.model_dump() for message in messages]

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
completion = client.chat.completions.create(
    model="glm-4v-9b",
    messages=messages,
)
print(completion.choices[0].message.content)
```

*è¾“å‡º*

```text
å›¾ç‰‡ä¸­çš„æ–‡å­—æœ‰â€œæ‚¦äº«å…ˆé”‹â€ã€â€œBçº§å…ˆé”‹çŒè£…SUVâ€ã€â€œå®‹Lâ€å’Œâ€œçŸ¥ä¹@ä¸ƒä¸‡é’£é‡‘ä¸­é‡Œæ¯…â€ã€‚

- â€œæ‚¦äº«å…ˆé”‹â€å’Œâ€œBçº§å…ˆé”‹çŒè£…SUVâ€æ˜¯å®‹Lè¿™æ¬¾è½¦çš„å®£ä¼ è¯­ï¼Œçªå‡ºäº†å…¶ä½œä¸ºä¸€æ¬¾Bçº§å…ˆé”‹çŒè£…SUVçš„ç‰¹ç‚¹ã€‚
- â€œå®‹Lâ€æ˜¯è¿™æ¬¾è½¦çš„åç§°ã€‚
- â€œçŸ¥ä¹@ä¸ƒä¸‡é’£é‡‘ä¸­é‡Œæ¯…â€å¯èƒ½æ˜¯å›¾ç‰‡æ¥æºæˆ–ä½œè€…çš„æ ‡æ³¨ã€‚
```

### Stream Chat Completion

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
completion = client.chat.completions.create(
    model="glm-4v-9b",
    messages=messages,
    stream=True,
)

answer = ""
for chunk in completion:
    content = chunk.choices[0].delta.content
    answer += content
print(answer)
```

*è¾“å‡º*

```text
å›¾ç‰‡ä¸­çš„æ–‡å­—æœ‰â€œæ‚¦äº«å…ˆé”‹â€ã€â€œBçº§å…ˆé”‹çŒè£…SUVâ€ã€â€œå®‹Lâ€å’Œâ€œçŸ¥ä¹@ä¸ƒä¸‡é’£é‡‘ä¸­é‡Œæ¯…â€ã€‚

å…¶ä¸­ï¼Œâ€œæ‚¦äº«å…ˆé”‹â€å’Œâ€œBçº§å…ˆé”‹çŒè£…SUVâ€æ˜¯å®‹Lè¿™æ¬¾è½¦çš„å®£ä¼ è¯­ï¼Œçªå‡ºäº†è¿™æ¬¾è½¦çš„ç‰¹ç‚¹å’Œå®šä½ï¼›â€œå®‹Lâ€æ˜¯è¿™æ¬¾è½¦çš„åç§°ï¼›â€œçŸ¥ä¹@ä¸ƒä¸‡é’£é‡‘ä¸­é‡Œæ¯…â€å¯èƒ½æ˜¯å›¾ç‰‡æ¥æºæˆ–ä½œè€…çš„æ ‡æ³¨ã€‚ 
```

### å¤šå›¾é—®ç­”

> å¯¹å¤šä¸ªå›¾ç‰‡è¿›è¡Œæ€»ç»“å›ç­”ï¼Œå½“å‰ä»…`mini_cpm-v2_6`æ”¯æŒã€‚

<div style="display: flex; justify-content: center;">
    <img src="img/llm/car-1.jpg" width="50%" style="margin-right: 10px;">
    <img src="img/llm/car-2.jpg" width="50%">
</div>

```python
from openai import OpenAI
from zlai.types.messages import ImageMessage, UserMessage, AssistantMessage

img_1 = "https://image11.m1905.cn/uploadfile/2008/1005/2006110205334520025.jpg"
img_2 = "https://pic2.zhimg.com/v2-70ea697c0edec518b9d513a49228e489_b.jpg"

messages = [
    UserMessage(content="ä½ å¥½"),
    AssistantMessage(content="ä½ å¥½"),
    ImageMessage(content="å¯¹æ¯”ä¸¤å¼ å›¾çš„å¼‚åŒï¼Œç»™å‡ºç»“è®ºã€‚", images_url=[img_1, img_2]),
]
messages = [message.model_dump() for message in messages]

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
completion = client.chat.completions.create(
    model="mini_cpm-v2_6",
    messages=messages,
    stream=True,
)

for chunk in completion:
    content = chunk.choices[0].delta.content
    print(content, flush=True, end='')
```

*è¾“å‡º*

```text
è¿™ä¸¤å¼ å›¾ç‰‡å±•ç¤ºçš„æ˜¯ä¸¤ç§ä¸åŒç±»å‹çš„è½¦è¾†ï¼Œä¸€ä¸ªæ˜¯åŠ¨ç”»ç”µå½±ä¸­çš„èµ›è½¦ï¼Œå¦ä¸€ä¸ªæ˜¯ç°å®ä¸–ç•Œä¸­çš„ç°ä»£SUVã€‚ä»¥ä¸‹æ˜¯å®ƒä»¬çš„å¼‚åŒå¯¹æ¯”ï¼š

### ç›¸åŒç‚¹ï¼š
1. **éƒ½æ˜¯æ±½è½¦**ï¼šä¸¤å¼ å›¾ç‰‡ä¸­çš„ä¸»ä½“éƒ½æ˜¯æ±½è½¦ã€‚
2. **è½¦è½®è®¾è®¡**ï¼šä¸¤è¾†è½¦éƒ½é…å¤‡äº†è½®èƒã€‚

### ä¸åŒç‚¹ï¼š
1. **é£æ ¼ä¸ç±»å‹**ï¼š
   - ç¬¬ä¸€å¼ å›¾ï¼ˆREF_1_FIGï¼‰å±•ç¤ºçš„æ˜¯ä¸€ä¸ªåŠ¨ç”»è§’è‰²ï¼Œå…·ä½“æ¥è¯´æ˜¯ä¸€ä¸ªç»¿è‰²çš„èµ›è½¦ï¼Œå…·æœ‰æ‹ŸäººåŒ–çš„è®¾è®¡ï¼Œæœ‰çœ¼ç›å’Œå˜´å·´ç­‰é¢éƒ¨ç‰¹å¾ã€‚
   - ç¬¬äºŒå¼ å›¾ï¼ˆREF_2_FIGï¼‰å±•ç¤ºçš„æ˜¯ä¸€è¾†ç°å®ä¸–ç•Œçš„SUVï¼Œå…·æœ‰ç°ä»£åŒ–çš„è®¾è®¡ï¼Œæ²¡æœ‰æ‹ŸäººåŒ–çš„ç‰¹å¾ã€‚

2. **é¢œè‰²å’Œå¤–è§‚**ï¼š
   - ç¬¬ä¸€å¼ å›¾çš„èµ›è½¦ä¸»è¦æ˜¯ç»¿è‰²ï¼Œå¸¦æœ‰å„ç§èµåŠ©å•†çš„æ ‡å¿—å’Œæ•°å­—â€œ86â€ã€‚
   - ç¬¬äºŒå¼ å›¾çš„SUVæ˜¯é“¶è‰²æˆ–æµ…è“è‰²ï¼Œè®¾è®¡æ›´åŠ ç®€æ´å’Œç°ä»£ã€‚

3. **ç¯å¢ƒèƒŒæ™¯**ï¼š
   - ç¬¬ä¸€å¼ å›¾çš„èƒŒæ™¯æ˜¯ä¸€ä¸ªèµ›è½¦åœºï¼Œå‘¨å›´æœ‰è®¸å¤šè§‚ä¼—å¸­ã€‚
   - ç¬¬äºŒå¼ å›¾çš„èƒŒæ™¯æ˜¯æ²™æ¼ ï¼Œæ˜¾ç¤ºäº†è¿™è¾†è½¦åœ¨æˆ·å¤–çš„ä½¿ç”¨åœºæ™¯ã€‚

4. **åŠŸèƒ½ç”¨é€”**ï¼š
   - ç¬¬ä¸€å¼ å›¾ä¸­çš„èµ›è½¦ä¸»è¦ç”¨äºç«æŠ€æ¯”èµ›ï¼Œå…·æœ‰é«˜æ€§èƒ½çš„ç‰¹ç‚¹ã€‚
   - ç¬¬äºŒå¼ å›¾ä¸­çš„SUVä¸»è¦ç”¨äºæ—¥å¸¸é©¾é©¶ï¼Œæ³¨é‡èˆ’é€‚æ€§å’Œå®ç”¨æ€§ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¿™ä¸¤å¼ å›¾ç‰‡å±•ç¤ºäº†ä¸åŒç±»å‹çš„æ±½è½¦ï¼Œä¸€ä¸ªæ˜¯ç”¨äºå¨±ä¹å’Œç«èµ›çš„åŠ¨ç”»è§’è‰²ï¼Œå¦ä¸€ä¸ªæ˜¯ç”¨äºæ—¥å¸¸ä½¿ç”¨çš„ç°ä»£SUVã€‚å®ƒä»¬åœ¨é£æ ¼ã€é¢œè‰²ã€ç¯å¢ƒå’ŒåŠŸèƒ½ä¸Šéƒ½æœ‰æ˜¾è‘—çš„ä¸åŒã€‚
```

## Vision

> å›¾åƒç”Ÿæˆä¸å›¾åƒç¼–è¾‘æ¨¡å‹

### Image Generate

> æ–‡ç”Ÿå›¾æ¨¡å‹`Text2Image`ï¼šæ ¹æ®æä¾›çš„`Prompt`æ¸²æŸ“ç”Ÿæˆå›¾ç‰‡ã€‚

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")

respose = client.images.generate(
    model="kolors_diffusers",
    prompt="é•¿åŸä¸‹é›ªå•¦ï¼Œå†™å”¯ç¾å®é£æ ¼ã€‚",
    size="1792x1024",
    response_format="b64_json",
)

from zlai.utils.image import *
trans_bs64_to_image(respose.data[0].b64_json)
```

*è¾“å‡º*

<center>
<img src="img/llm/kolors-diffusers-01.png" width="100%">
</center>

### Image Edit

> å›¾ç”Ÿå›¾æ¨¡å‹`Image2Image`ï¼šæ ¹æ®æä¾›çš„å›¾ç‰‡å’Œ`Prompt`å¯¹å›¾ç‰‡è¿›è¡Œç¼–è¾‘ã€‚

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")

respose = client.images.edit(
    model="kolors_image2image",
    prompt="å®«å´éªå¡é€šé£æ ¼",
    image=open("./data/top-20-small-dog-breeds.jpeg", "rb"),
    size="1024x1024",
    response_format="b64_json",
)
```

*è¾“å‡º*

<div style="display: flex; justify-content: center;">
    <div>
        <center>
        <img src="img/llm/kolors-diffusers-02.png" width="80%" style="margin-right: 10px;">
        <br>
        åŸå§‹å›¾
        </center>
    </div>
    <div>
        <center>
        <img src="img/llm/kolors-diffusers-03.png" width="83%">
        <br>
        ç”Ÿæˆå›¾
        </center>
    </div>
</div>

## Audio

> æ–‡å­—è½¬è¯­éŸ³ `TTS(text to speech)`

### TTS

> `voice`: éŸ³è‰²æœ‰`['ä¸­æ–‡å¥³', 'ä¸­æ–‡ç”·', 'æ—¥è¯­ç”·', 'ç²¤è¯­å¥³', 'è‹±æ–‡å¥³', 'è‹±æ–‡ç”·', 'éŸ©è¯­å¥³']`

```python
from openai import OpenAI
client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")

text = """
æœ‰æ—¶,æˆ‘ä¼šé™é™åœ°ååœ¨åº­é™¢é‡Œ,çœ‹ç€è½å¶é£˜é£,æ„Ÿæ…¨ä¸‡åƒã€‚é’æ˜¥æ— ç—•,æ—¥å­å¦‚ç™½é©¹è¿‡éš™ã€‚
æˆ‘ä»¬æ›¾ç»å¤šä¹ˆæ˜æœ—ä¸”æ— å¿§æ— è™‘,å¦‚ä»Šå´é€æ¸å˜å¾—æ²§æ¡‘å’Œè¿·æƒ˜ã€‚ç”Ÿå‘½åƒä¸€æœµèŠ±,æ˜æ˜ç¿çƒ‚åœ°ç»½æ”¾,æœ€ç»ˆå´ä¹Ÿæ¯èå‡‹è°¢ã€‚
"""

speech_file_path = "./audio.wav"
response = client.audio.speech.create(model="CosyVoice-300M-SFT", voice="ä¸­æ–‡å¥³", input=text)

response.stream_to_file(speech_file_path)
```

*è¾“å‡º*

<audio controls>
  <source src="audio/audio.wav" type="audio/mpeg">
</audio>

## Embedding

### Text Embedding

> æ–‡æœ¬åµŒå…¥æ¨¡å‹`Embedding`ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ã€‚

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")

response = client.embeddings.create(input=["ä½ å¥½"], model="bge-m3")
print(len(response.data[0].embedding))
print(response.usage)
print(response.data[0].embedding[:5])
```

*è¾“å‡º*

```text
1024
Usage(prompt_tokens=0, total_tokens=2)
[-0.037132877856492996, 0.006196103058755398, -0.06525908410549164, -0.02504667080938816, -0.016926351934671402]
```

## End

------

æœ¬å°èŠ‚ç½—åˆ—äº†å¯ä»¥æœ¬åœ°éƒ¨ç½²çš„å¼€æºå¤§æ¨¡å‹ API Listï¼Œå¦‚æœæ‚¨è‡ªå·±æœ‰è‡ªå·±çš„GPUè®¡ç®—èµ„æºï¼Œå°±å¯ä»¥éƒ¨ç½²è‡ªå·±æœ¬åœ°åŒ–çš„æ¨¡å‹æœåŠ¡ï¼Œä¸ä¾èµ–äºçº¿ä¸Šçš„å¤§æ¨¡å‹APIæ¥å£ã€‚åœ¨`zlai`ä¸­åœ¨çº¿æ¨¡å‹ä¸æœ¬åœ°æ¨¡å‹ä½¿ç”¨æ–¹å¼å®Œå…¨ä¸€è‡´ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©ä½¿ç”¨ã€‚

**Tips**: *å…¶ä»–æ–¹æ³•å¦‚`Message`æ¨ç†ï¼Œæ¨¡å‹è¾“å‡ºæ•°æ®ç±»å‹ã€è¾“å‡ºç»“æœçš„è§£æéƒ½ä¸å‰é¢çº¿ä¸Šè°ƒç”¨æ¨¡å‹çš„ä½¿ç”¨æ–¹å¼ä¸€è‡´ã€‚è¿™é‡Œä¸åšæ›´ä¸ºç»†è‡´çš„å±•å¼€ã€‚è¯¦ç»†çš„`Message`ç®¡ç†æœºåˆ¶ï¼Œè¯·[å‚è€ƒ](/doc/zlai-message-01.md)*
