# å¼€æºå¤§æ¨¡å‹éƒ¨ç½²

> ZLAIåœ¨ç‰ˆæœ¬(0.3.104+)åä¼šé™†ç»­æ”¯æŒæœ¬åœ°åŒ–éƒ¨ç½²å¤§æ¨¡å‹ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºChatGLMã€Qwenã€LLaMAã€Baichuanç­‰ï¼Œå¹¶ä»¥`OpenAI`çš„æ¥å£å½¢å¼æä¾›ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿæ¥å…¥å’Œä½¿ç”¨ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ”¯æŒå¿«é€Ÿä¸ZLAIçš„å…¶å®ƒåŠŸèƒ½è¿›è¡Œæ•´åˆï¼Œä¾‹å¦‚`ZLAI`çš„`Embedding`ã€`Agent`ã€`Prompt`ã€`LLM`ã€`Chat`ç­‰ã€‚

## éƒ¨ç½²æ–¹å¼

> éƒ¨ç½²æ–¹å¼

```bash
# æ›´æ–° ZLAI Package
pip install zlai["local"] -U

# å¯åŠ¨æœ¬åœ°åŒ–éƒ¨ç½²
zlai_models --config_path "./models_config.yml" --reload=0 --port=8000 --host "0.0.0.0"
```

> éƒ¨ç½²å‚æ•°

- `config_path`: æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé…ç½®æ–‡ä»¶[å‚è€ƒ](https://github.com/zlai-llm/zlai/blob/master/models_config.yml)
- `reload`: åœ¨ä»£ç æˆ–æ–‡ä»¶æ›´æ–°åAPIæ˜¯å¦çƒ­æ›´æ–°ï¼Œé»˜è®¤ä¸º`0`ï¼Œä¸è‡ªåŠ¨åŠ è½½æ›´æ–°
- `port`: APIæœåŠ¡ç«¯å£ï¼Œé»˜è®¤ä¸º`8000`
- `host`: APIæœåŠ¡åœ°å€ï¼Œé»˜è®¤ä¸º`localhost`ï¼ŒæŒ‡å®šä¸º`0.0.0.0`åå¯ä»¥é€šè¿‡`IP`è®¿é—®

> [é…ç½®æ–‡ä»¶è¯´æ˜](https://github.com/zlai-llm/zlai/blob/master/models_config.yml)

```yaml
models_config:
  - model_name: Qwen2-0.5B-Instruct                      # æ¨¡å‹åç§°
    model_path: /home/models/Qwen/Qwen2-0.5B-Instruct    # æ¨¡å‹æ–‡ä»¶è·¯å¾„
    model_type: completion                               # æ¨¡å‹ç±»å‹ï¼Œç›®å‰æ”¯æŒ`completion`ã€`embedding`
    load_method: load_qwen2                              # åŠ è½½æ¨¡å‹æ–¹æ³•ï¼Œç›®å‰æ”¯æŒ`load_qwen2`ã€`load_glm4`
    max_memory:                                          # æ¨¡å‹æœ€å¤§æ˜¾å­˜
      0: "2GB"
  - model_name: Qwen2-1.5B-Instruct
    model_path: /home/models/Qwen/Qwen2-1.5B-Instruct
    model_type: completion
    load_method: load_qwen2
    max_memory:
      0: "4GB"
```

## API-Doc

> [http://localhost:8000/docs](http://localhost:8000/docs)

<center>
<img src="img/llm/zlai-llm-openai-api-doc.png" width="100%">
</center>

## æ¨¡å‹åˆ—è¡¨

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
models_list = client.models.list()
print(models_list.data)
```

*è¾“å‡º*

```text
[Model(id='Qwen2-0.5B-Instruct', created=None, object='model', owned_by='Open Source'),
 Model(id='Qwen2-1.5B-Instruct', created=None, object='model', owned_by='Open Source'),
 Model(id='Qwen2-7B-Instruct', created=None, object='model', owned_by='Open Source'),
 Model(id='Qwen2-57B-A14B-Instruct-GPTQ-Int4', created=None, object='model', owned_by='Open Source'),
 Model(id='glm-4-9b-chat', created=None, object='model', owned_by='Open Source'),
 Model(id='glm-4-9b-chat-1m', created=None, object='model', owned_by='Open Source'),
 Model(id='glm-4v-9b', created=None, object='model', owned_by='Open Source')]
```

## æ¨¡å‹è¯·æ±‚

### Normal Completion

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
completion = client.chat.completions.create(
    model="glm-4-9b-chat",
    messages=[
        {"role": "user", "content": "ä½ å¥½"},
    ],
    stream=False
)
print(completion.choices[0].message.content)
```

*è¾“å‡º*

```text
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
```

### Stream Completion

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
completion = client.chat.completions.create(
    model="glm-4-9b-chat",
    messages=[
        {"role": "user", "content": "ä½ å¥½"},
    ],
    stream=True
)

answer = ""
for chunk in completion:
    content = chunk.choices[0].delta.content
    answer += content
    print(answer)
```

*è¾“å‡º*

```text
ä½ å¥½
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ 
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆ
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—
ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ 
```

## Function Call

> tools example

```python
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "Get the current weather",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    },
                    "format": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "The temperature unit to use. Infer this from the users location.",
                    },
                },
                "required": ["location", "format"],
            },
        }
    },
]
```

### Normal Function Call

#### Function Call

> code

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000")
completion = client.chat.completions.create(
    model="glm-4-9b-chat",
    messages=[
        {"role": "user", "content": "What's the Celsius temperature in San Francisco?"},
    ],
    tools=tools,
    tool_choice="auto",
    stream=False,
)
print(completion.choices[0].message.tool_calls[0].function.name)
print(completion.choices[0].message.tool_calls[0].function.arguments)
```

*è¾“å‡º*

```text
get_current_weather

{"location": "San Francisco, CA", "format": "celsius"}
```

#### Call Function

```python
from zlai.types.messages import ToolMessage

messages=[
    UserMessage(content="What's the Celsius temperature in San Francisco?"),
    completion.choices[0].message,
    ToolMessage(content="{San Francisco, CA: {celsius: 15}}"),
]

completion = client.chat.completions.create(
    model="glm-4-9b-chat", messages=messages,
    tools=tools, tool_choice="auto", stream=False,
)
```

*è¾“å‡º*

```text
The current Celsius temperature in San Francisco is 15 degrees.
```

### Stream Function Call

#### Function Call

> code

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://192.168.98.240:8000")
completion = client.chat.completions.create(
    model="glm-4-9b-chat",
    messages=[
        {"role": "user", "content": "What's the Celsius temperature in San Francisco?"},
    ],
    tools=tools,
    tool_choice="auto",
    stream=True,
)

answer = ""
for chunk in completion:
    content = chunk.choices[0].delta.content
    if content:
        answer += content
        print(answer)
```

*è¾“å‡º*

```text
 get_current_weather

 get_current_weather
{"location": 
 get_current_weather
{"location": "San 
 get_current_weather
{"location": "San Francisco, 
 get_current_weather
{"location": "San Francisco, CA", 
 get_current_weather
{"location": "San Francisco, CA", "format": 
 get_current_weather
{"location": "San Francisco, CA", "format": "celsius"} 
```

> Function Call Parameters

```python
print("content: ", chunk.choices[0].delta.content)
if chunk.choices[0].delta.tool_calls:
    print("function name: ", chunk.choices[0].delta.tool_calls[0].function.name)
    print("function arguments: ", chunk.choices[0].delta.tool_calls[0].function.arguments)
```

*è¾“å‡º*

```text
content:  None
function name:  get_current_weather
function arguments:  {"location": "San Francisco, CA", "format": "celsius"}
```

#### Call Function

```python
from zlai.types.messages import ToolMessage

messages=[
    UserMessage(content="What's the Celsius temperature in San Francisco?"),
    completion.choices[0].message,
    ToolMessage(content="{San Francisco, CA: {celsius: 15}}"),
]

completion = client.chat.completions.create(
    model="glm-4-9b-chat", messages=messages, tools=tools, 
    tool_choice="auto", stream=True, 
)

answer = ""
for chunk in completion:
    content = chunk.choices[0].delta.content
    if content:
        answer += content
        print(answer)
```

*è¾“å‡º*

```text
The 
The current 
The current Celsius 
The current Celsius temperature 
The current Celsius temperature in 
The current Celsius temperature in San 
The current Celsius temperature in San Francisco 
The current Celsius temperature in San Francisco is 
The current Celsius temperature in San Francisco is 15  
The current Celsius temperature in San Francisco is 15 degrees. 
```

## å¤šæ¨¡æ€æ¨¡å‹

**Example**: `glm-4v-9b`
**Image**: [Image](https://pic2.zhimg.com/v2-70ea697c0edec518b9d513a49228e489_b.jpg)

### Normal Completion

```python
from openai import OpenAI
from zlai.types.messages import ImageMessage, UserMessage, AssistantMessage

messages = [
    ImageMessage(content="è§£æå›¾ç‰‡ä¸­çš„æ–‡å­—").add_image(url="https://pic2.zhimg.com/v2-70ea697c0edec518b9d513a49228e489_b.jpg"),
]
messages = [message.model_dump() for message in messages]

client = OpenAI(api_key="EMPTY", base_url="http://192.168.98.240:8000")
completion = client.chat.completions.create(
    model="glm-4v-9b",
    messages=messages,
)
print(completion.choices[0].message.content)
```

*è¾“å‡º*

```text
å›¾ç‰‡ä¸­çš„æ–‡å­—æœ‰â€œæ‚¦äº«å…ˆé”‹â€ã€â€œBçº§å…ˆé”‹çŒè£…SUVâ€ã€â€œå®‹Lâ€å’Œâ€œçŸ¥ä¹@ä¸ƒä¸‡é’£é‡‘ä¸­é‡Œæ¯…â€ã€‚

- â€œæ‚¦äº«å…ˆé”‹â€å’Œâ€œBçº§å…ˆé”‹çŒè£…SUVâ€æ˜¯å®‹Lè¿™æ¬¾è½¦çš„å®£ä¼ è¯­ï¼Œçªå‡ºäº†å…¶ä½œä¸ºä¸€æ¬¾Bçº§å…ˆé”‹çŒè£…SUVçš„ç‰¹ç‚¹ã€‚
- â€œå®‹Lâ€æ˜¯è¿™æ¬¾è½¦çš„åç§°ã€‚
- â€œçŸ¥ä¹@ä¸ƒä¸‡é’£é‡‘ä¸­é‡Œæ¯…â€å¯èƒ½æ˜¯å›¾ç‰‡æ¥æºæˆ–ä½œè€…çš„æ ‡æ³¨ã€‚
```

### Stream Comletion

```python
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://192.168.98.240:8000")
completion = client.chat.completions.create(
    model="glm-4v-9b",
    messages=messages,
    stream=True,
)

answer = ""
for chunk in completion:
    content = chunk.choices[0].delta.content
    answer += content
print(answer)
```

*è¾“å‡º*

```text
å›¾ç‰‡ä¸­çš„æ–‡å­—æœ‰â€œæ‚¦äº«å…ˆé”‹â€ã€â€œBçº§å…ˆé”‹çŒè£…SUVâ€ã€â€œå®‹Lâ€å’Œâ€œçŸ¥ä¹@ä¸ƒä¸‡é’£é‡‘ä¸­é‡Œæ¯…â€ã€‚

å…¶ä¸­ï¼Œâ€œæ‚¦äº«å…ˆé”‹â€å’Œâ€œBçº§å…ˆé”‹çŒè£…SUVâ€æ˜¯å®‹Lè¿™æ¬¾è½¦çš„å®£ä¼ è¯­ï¼Œçªå‡ºäº†è¿™æ¬¾è½¦çš„ç‰¹ç‚¹å’Œå®šä½ï¼›â€œå®‹Lâ€æ˜¯è¿™æ¬¾è½¦çš„åç§°ï¼›â€œçŸ¥ä¹@ä¸ƒä¸‡é’£é‡‘ä¸­é‡Œæ¯…â€å¯èƒ½æ˜¯å›¾ç‰‡æ¥æºæˆ–ä½œè€…çš„æ ‡æ³¨ã€‚ 
```

## å·²ç»é€šè¿‡æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨

| ç³»åˆ—    | æ¨¡å‹                                | æ™®é€šæ¨ç† | æµå¼æ¨ç† | FunctionCall |
|-------|-----------------------------------|------|------|--------------|
| Qwen2 | Qwen2-0.5B-Instruct               | âœ”ï¸   | âœ”ï¸   | æš‚ä¸æ”¯æŒ         |
| Qwen2 | Qwen2-1.5B-Instruct               | âœ”ï¸   | âœ”ï¸   | æš‚ä¸æ”¯æŒ         |
| Qwen2 | Qwen2-7B-Instruct                 | âœ”ï¸   | âœ”ï¸   | æš‚ä¸æ”¯æŒ         |
| Qwen2 | Qwen2-57B-A14B-Instruct-GPTQ-Int4 | âœ”ï¸   | âœ”ï¸   | æš‚ä¸æ”¯æŒ         |
| GLM4  | glm-4-9b-chat                     | âœ”ï¸   | âœ”ï¸   | âœ”ï¸           |
| GLM4  | glm-4-9b-chat-1m                  | âœ”ï¸   | âœ”ï¸   | âœ”ï¸           |
| GLM4  | glm-4v-9b                         | âœ”ï¸   | âœ”ï¸   | âœ”ï¸           |

## End

------
