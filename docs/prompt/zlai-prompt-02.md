# 大模型参数与Prompt

> 虽然在前面的介绍中多少已经涉及到了Prompt提示词的内容，在本小节将会系统的介绍Prompt，什么是Prompt，我们该怎么使用Prompt完成各种各样的任务。

除非另有说明，本指南默认所有示例都是在使用 `智谱AI` 的 `glm-3-turbo` 进行测试。模型使用默认配置，即 `temperature=0.95` 和 `top_p=0.7`。一般而言，这些提示词也应适用于其他大模型，如`gpt-3.5-turbo`，但不同模型的回答结果可能会有所不同，这不影响本章节要讨论的内容。

## 什么是提示词`Prompt`?

在一切开始之前，我们需要先了解大语言模型的工作原理。大模型简单来讲就是通过对给定的文本来预测下一个词，然后重复这个过程，知道输出到结束标识符或达到最大的生成长度。

提示词（`Prompt`）是指导大语言模型生成结果的文本。大语言模型根据提示词生成结果，模型生成结果的质量与您提供信息（`prompt`）的质量和完善度有关。一个提示词可以包含您传递给模型的`指令`或`问题`等信息，也可以包含其他的补充信息，如上下文`content`、输入`input`或示例`examples`等。您可以通过合理组织这些信息元素来更好地指导模型获得更好的结果。

比如，我们可以`杭州市`为提示词，让大模型以此续写有关于杭州的一句话。

> 提示词

```text
from zlai.llms import Zhipu, ZhipuGLM3Turbo

llm = Zhipu(generate_config=ZhipuGLM3Turbo(stop=["。"]))
completion = llm.generate(query="杭州市")
print(f"Assistant: {completion.choices[0].message.content}")
print(f"Tokens: {completion.usage.completion_tokens}")
```

*Tips: `stop=["。"]`参数是指模型输出至句号`。`的时候停止，用于精准控制输出一句话。`completion.usage.completion_tokens`是这一次推理输出的`tokens`数量。*

> 输出结果

```text
Assistant: 杭州市，是浙江省的省会，也是一个重要的经济、文化、科教中心，同时还是长江三角洲中心城市之一。
Tokens: 25
```

从上面的提示示例中可以看出，语言模型能够基于我们给出的 `杭州市` 完成续写。在实际的使用场景中也许我们可以通过更为精准的提示`Prompt`来让模型生成更好的结果。

让我们试着改进以下：

> 提示词

```text
from zlai.llms import Zhipu, ZhipuGLM3Turbo

llm = Zhipu(generate_config=ZhipuGLM3Turbo(stop=["。"]))
query = """
请以杭州市为开头，生成一句关于杭州市的介绍，要重点介绍西湖的旅游资源。

杭州市
"""

completion = llm.generate(query=query)
print(f"Assistant: {completion.choices[0].message.content}")
print(f"Tokens: {completion.usage.completion_tokens}")
```

> 输出结果

```text
Assistant: 杭州市，浙江省省会，是中国历史文化名城，以美丽的西湖闻名于世。
Tokens: 17
```

你看，模型按照我们的要求将西湖加入到了新生成的句子中。这只是一个非常简单的示例，**提示工程**（`Prompt Engineering`）就是探讨如何设计出最佳提示词，用于指导语言模型帮助我们高效完成某项任务。以上示例基本说明了现阶段的大语言模型能够发挥的功能作用的前提。在后续的任务中，我们将会逐步介绍如何设计提示词工程，执行各种高级任务，如文本概括、数学推理、代码生成、甚至是Agent等等。

## 提示词格式应该遵循什么标准？

前文中我们还是采取的比较简单的提示词。都是以单一的问题或者指令提出，类似于下面的格式：

```text
<问题/指令>?
```

> 好的提示词应该具备哪些要素？

如果您接触过大量提示工程相关的示例和应用，您会注意到提示词是由一些要素组成的。好的提示词可以包含以下任意要素：

1. **指令**：想要模型执行的特定任务或指令。
2. **上下文**：包含外部信息或额外的上下文信息，引导语言模型更好地响应。
3. **输入数据**：用户输入的内容或问题。
4. **输出指示**：指定输出的类型或格式。

为了更好地演示提示词要素，下面是一个简单的提示，旨在完成文本分类任务：

```text
请将文本分为中性、否定或肯定
文本：我觉得食物还可以。
情绪：
```

在上面的提示示例中，指令是`将文本分类为中性、否定或肯定`。输入数据是`我认为食物还可以`部分，使用的输出指示是`情绪：`。 注意，提示词所需的格式取决于您想要语言模型完成的任务类型，并非所有以上要素都是必须的。

> `zero-shot`

以上的提示方式，也被称为 `零样本提示`（`zero-shot prompting`），即用户不提供任务结果相关的示范，直接提示语言模型给出任务相关的回答。大型语言模式有能力实现零样本提示，但这也取决于任务的复杂度和模型已有的知识范围。`zero-shot` 的提问方式可以被优化为下面这种格式：

```text
Q: <问题>?
A: 
```

*具体的零样本提示示例如下：*

```text
Q: 中国的首都是哪里?
```

对于一些较新或者较为聪明的模型，你可以跳过 `Q:` 部分，直接输入问题。因为模型在训练过程中被训练并理解问答任务，换言之，提示词可以简化为下面的形式：

提示词

```text
中国的首都是哪里?
```

> Few-shot Prompting

基于以上标准范式，目前业界普遍使用的还是更高效的小样本提示（`Few-shot Prompting`）范式，即用户提供少量的提示范例，如任务说明等。小样本提示一般遵循以下格式：

```text
<问题>?
<答案>
<问题>?
<答案>
<问题>?
<答案>
<问题>?
```

或者：

```text
Q: <问题>?
A: <答案>
Q: <问题>?
A: <答案>
Q: <问题>?
A: <答案>
Q: <问题>?
A:
```

注意，使用问答模式`Q/A`并不是必须的。你可以根据任务需求调整提示范式。下面是一个简单的例子，假设我要执行一个简单的分类任务：

*提示词*

```python
from zlai.llms import Zhipu, ZhipuGLM3Turbo

llm = Zhipu(generate_config=ZhipuGLM3Turbo())
query = """
你需要判断句子的情感倾向，输出Positive/Negative，不要输出其他内容，以下是三个示例：

景色真实太好了! // Positive
这里太乱了! // Negative
真个电影真好看! // Positive

车开的实在是太慢了! //
"""

completion = llm.generate(query=query)
print(f"Assistant: {completion.choices[0].message.content}")
```

*输出结果*

```text
Assistant: Negative
```

语言模型可以基于一些说明了解和学习某些任务，而小样本提示正好可以赋能上下文学习能力。我们将在接下来的章节中更广泛的讨论如何使用零样本提示和小样本提示。

## 设计提示的通用技巧

> 从简单开始

在设计提示时，需要记住这是一个迭代的过程，需要大量的实验来获得最佳结果。您可以从简单的提示开始，不断添加更多的提示元素和上下文。在此过程中对您的提示进行版本控制是至关重要的。当您阅读本指南时，您会看到许多例子，其中具体性、简洁性和简明性通常会给您带来更好的结果。

此外，当您有一个涉及许多不同子任务的大任务时，您可以尝试将任务分解为更简单的子任务，
并随着获得更好的结果而不断重构。这避免了在提示设计过程中一开始就添加过多的复杂性。

> 指令

您可以使用命令来指示模型执行各种简单任务，例如“写入”、“分类”、“总结”、“翻译”、“排序”等，从而为各种简单任务设计有效的提示。您还需要进行大量的实验，尝试使用不同的关键字、上下文，尝试不同的指令，看看哪种方法最适合您的特定用例和任务。通常情况下，上下文与您要执行的任务越具体和相关，效果越好。其他建议将指令放在提示的开头，使用一些清晰的分隔符，如“```”，来分隔指令和上下文，可能可以起到一定的效果。如：

```text
你是一个翻译机器人，将以下文本翻译成中文：
文本：```hello！```
```

> 具体性

提示越具体越详细，结果就越好。更重要的是具有良好的格式和描述性提示。例如，让我们尝试从一段文本中提取特定信息的简单提示。

```python
from zlai.llms import Zhipu, ZhipuGLM3Turbo

llm = Zhipu(generate_config=ZhipuGLM3Turbo())
query = """
请提取出下面文本的地点，以List输出，不需要输出其他内容。

文本：虽然这些发展对研究人员来说是令人鼓舞的，但仍有许多谜团。里斯本未知的香帕利莫德中心的神经免疫学家 Henrique Veiga-Fernandes 说：“我们经常在大脑和我们在周围看到的效果之间有一个黑匣子。”“如果我们想在治疗背景下使用它，我们实际上需要了解机制。
"""

completion = llm.generate(query=query)
print(f"Assistant: {completion.choices[0].message.content}")
```

输出：

```text
Assistant: List: ['里斯本', '香帕利莫德中心']
```

上面的示例中，我们给大模型的指令是`取出下面文本的地点，以List输出，不需要输出其他内容。`，模型精准找出了文本中的地点内容，并以`List`格式做了输出。输入文本来自这篇[Nature]((https://www.nature.com/articles/d41586-023-00509-z))文章。

> 简洁明了，避免不精确

在上面关于详细和格式改进的提示中，很容易陷入做出更复杂的Prompt提示，想让大模型做出更复杂和过于聪明的提示陷阱，从而创建不精确的描述。而提示词通常最好是具体和直接的，越是简单有效的沟通，信息传递就越有效。例如，您可能有兴趣了解提示工程的概念。您可以尝试这样提问：

```text
解释提示工程的概念。保持解释简短，只有几句话，不要过于描述。
```

从上面的提示中不清楚要使用多少句话和什么样的风格。您可能仍然可以通过上面的提示获得良好的响应，但更好的提示是非常具体、简洁和直接的。例如：

```text
使用 2-3 句话向高中学生解释提示工程的概念。
```

此外，设计提示时的另一个常见技巧是避免说不要做什么，而是说要做什么。

提示词设计，还是以应当以实际的应用场景为基础反复的探索，不断迭代，最终获得最佳的结果。

------
@2024/04/29
