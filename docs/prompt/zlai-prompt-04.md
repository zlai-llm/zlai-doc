# Few-shot提示

对于绝大多数的自回归问答模型，由于其逐个`token`的预测方式，改进提示词显然有助于在不同任务上获得更好的结果，即通过优化提示词的方式使得模型输出的结果更加符合任务要求，这就是提示工程背后的整个理念。但在本节中，我们将介绍更高级的提示工程技术，使我们能够完成更复杂和有趣的任务。

## 零样本提示

> 零样本提示`zero-shot`即不给定模型任何提示，让模型直接进行任务结果的输出。

如今，经过大量数据训练并进行过指令微调对齐过的LLM能够一定程度上执行零样本任务。我们在前一节中也尝试了一些零样本示例。以下是我们使用的一个示例：

*提示：*

```text
将文本分类为中性、负面或正面。
文本：我认为这次假期还可以。
情感：
```

*输出：*

```text
中性
```

**Tips:** 
*指令调整已被证明可以改善零样本学习[Wei等人（2022）](https://arxiv.org/pdf/2109.01652.pdf)。指令调整本质上是在通过指令描述的数据集上微调模型的概念。此外，[RLHF](https://arxiv.org/abs/1706.03741)（来自人类反馈的强化学习）已被采用以扩展指令调整，其中模型被调整以更好地适应人类偏好。这一最新发展推动了像ChatGPT这样的模型。我们将在接下来的章节中讨论所有这些方法和方法。*

## 少样本提示

> 什么是少样本提示？

当零样本不起作用时，少样本提示`few-shot`也许可以从一定程度上解决问题。虽然大型语言模型展示了惊人的零样本能力，但它们在复杂的任务上仍然表现不佳。少样本提示可以作为一种提示技术，使得模型启用上下文学习，在我们给定的示例中引导模型实现更好的结果。

根据 [Touvron et al. 2023](https://arxiv.org/pdf/2302.13971.pdf)等人的在 2023 年的论文，当模型规模足够大时，小样本提示特性开始出现 [(Kaplan et al., 2020)](https://arxiv.org/abs/2001.08361)。让我们通过[Brown等人2020年](https://arxiv.org/abs/2005.14165)提出的一个例子来演示少样本提示。在这个例子中，任务是在句子中正确使用一个新词。这里我们改写为使用中文的形式，正确的使用成语。

*示例-使用`zero-shot`*

```python
from zlai.llms import Zhipu, ZhipuGLM4

query = """
【成语】陈母问勇
【解释】陈祥榕为国捐躯后，母亲询问儿子在战场上是否勇敢。组织上来慰问陈母，问有啥需要解决的问题，需要帮忙的地方没。陈母没回答问题，反问了一句：我儿当时勇敢吗。陈母无求，但问吾儿勇否。
【寓意】信念坚定不计生死。

请使用成语'陈母问勇'，造句。
"""

llm = Zhipu(generate_config=ZhipuGLM4())
completion = llm.generate(query=query)
print(f"Assistant: {completion.choices[0].message.content}")
print(f"Tokens: {completion.usage.completion_tokens}")
```

*输出*

```text
Assistant: 在纪念英雄陈祥榕的座谈会上，许多人都被他的母亲“陈母问勇”的故事深深打动，她不在乎物质上的帮助，只关心儿子是否在战场上展现了勇气，这份信念坚定、不计生死的崇高精神感染了在场的每一个人。 

造句：面对困难，我们应当学习陈母问勇的精神，坚定信念，勇往直前。
Tokens: 81
```

上面的示例中，我们并未给定任何参考示例，模型似乎简单的解释了一些这个成语的出处与含义，并输出了一个简单的造句，但这似乎并不符合我们的预期。

*示例-使用`one-shot`*

```python
from zlai.llms import Zhipu, ZhipuGLM4

query = """
【成语】陈母问勇
【解释】陈祥榕为国捐躯后，母亲询问儿子在战场上是否勇敢。组织上来慰问陈母，问有啥需要解决的问题，需要帮忙的地方没。陈母没回答问题，反问了一句：我儿当时勇敢吗。陈母无求，但问吾儿勇否。
【寓意】信念坚定不计生死。

请使用成语'陈母问勇'，造句。
参考示例：此行远去，当有陈母问勇的决心，若成功，再与诸君共饮。

请使用成语'陈母问勇'，造句。
"""

llm = Zhipu(generate_config=ZhipuGLM4())
completion = llm.generate(query=query)
print(f"Assistant: {completion.choices[0].message.content}")
print(f"Tokens: {completion.usage.completion_tokens}")
```

*输出*

```text
Assistant: 在这个项目中，我们面临着巨大的挑战，但我坚信只要我们全体成员都怀着陈母问勇的坚定信念，共同努力，必定能够克服一切困难，取得最终的胜利。
Tokens: 38
```

我们可以观察到，模型通过提供一个示例（即`1-shot`）已经学会了如何执行任务，并输出了一个相对符合场景的句子。对于更困难更复杂的任务，我们可以尝试增加演示（例如`3-shot`、`5-shot`、`10-shot`等）。

根据[Min等人（2022）](https://arxiv.org/abs/2202.12837)的研究结果，使用了12种不同的模型，包括从774M到175B不等的模型大小，并在26个低资源数据集上进行了评估，涵盖了情感分析、文本复述检测、自然语言推理、仇恨言论检测、问答和句子完成等多种任务。研究的关键发现包括：

- 示例的真实性并不重要：即使在示例中用随机标签替换真实标签，模型在一系列分类和多项选择任务上的性能也只是轻微下降。这与使用真实标签的示例相比，性能下降范围在0-5%之间。
- 示例的其他方面是关键：示例中的关键因素包括它们提供的标签空间的示例、输入文本的分布以及整体序列格式。
- 使用与真实标签分布相同的示例：从真实标签分布（而不是均匀分布）中选择随机标签也有帮助。
- 论文还探讨了在没有足够标注数据的情况下，如何通过上下文学习来提高零样本性能。

下面是一个随机标签的例子，标签`Negative`和`Positive`随机分配给输入：

*提示：*

```python
from zlai.llms import Zhipu, ZhipuGLM4

query = """
你需要对文本进行情感分类。

示例：
这太棒了！// Negative
这太糟糕了！// Positive
哇，那部电影太棒了！// Positive

请对下面句子进行分类：
多么可怕的节目！//"""

llm = Zhipu(generate_config=ZhipuGLM4(stop=["\n\n"]))
completion = llm.generate(query=query)
print(f"Assistant: {completion.choices[0].message.content}")
print(f"Tokens: {completion.usage.completion_tokens}")
```

*输出：*

```text
Assistant: Negative (负面情感)
Tokens: 7
```

**可以看到即使标签已经随机化，我们仍然得到了正确的答案。** 在上面的例子中，我们从一定程度上还保留了样例的格式（`句子 // 分类`），这也有助于模型输出正确的结果。下面我们进一步实验观察是否使用混乱的格式也能获取正确的输出。例如：

*提示：*

```python
from zlai.llms import Zhipu, ZhipuGLM4

query = """
你需要对文本进行情感分类。

示例：
Negative 这太棒了！
这太糟糕了！Positive
哇，那部电影太棒了！
Positive

请对下面句子进行分类：
多么可怕的节目！"""

llm = Zhipu(generate_config=ZhipuGLM4(stop=["\n\n"]))
completion = llm.generate(query=query)
print(f"Assistant: {completion.choices[0].message.content}")
print(f"Tokens: {completion.usage.completion_tokens}")
```

*输出：*

```text
Assistant: Negative
Tokens: 3
```

上面的格式不一致，但模型仍然预测了正确的标签。

## 少样本提示的限制

标准的少样本提示对许多任务都有效，但仍然不是一种完美的技术，特别是在处理更复杂的推理任务时。下面是一个更为复杂的示例，让模型找出一组数字中的奇数，并判断他们的和是否是偶数。

*提示：*

```python
from zlai.llms import Zhipu, ZhipuGLM3Turbo

query = """这组数字中的奇数加起来是一个偶数：15、32、5、13、82、7、1。
A："""

llm = Zhipu(generate_config=ZhipuGLM3Turbo())
completion = llm.generate(query=query)
print(f"Assistant: {completion.choices[0].message.content}")
```

*模型输出如下：*

```text
Assistant: 让我们将给定的数字相加：15 + 32 + 5 + 13 + 82 + 7 + 1。

首先，我们可以将一些数字相加，看看是否能得到一个偶数。例如，我们可以将15和5相加，得到20（一个偶数）。接着，我们可以将13和7相加，得到20（同样是一个偶数）。然后，我们可以将32和82相加，得到114（也是一个偶数）。

现在，我们将这三个偶数相加：20 + 20 + 114 = 154。

最后，我们还有一个奇数1没有加进去。如果我们把1加到154上，我们得到155。155是一个奇数。

因此，根据给定的数字，奇数相加的结果是一个奇数，而不是偶数。

所以，这个陈述是错误的。
```

模型同常不能给出正确的答案，让我们尝试添加一些示例，看看少样本提示是否可以改善结果。

*提示：*

```text
from zlai.llms import Zhipu, ZhipuGLM3Turbo

query = """
这组数字中的奇数加起来是一个偶数：4、8、9、15、12、2、1。
A：答案是False。
这组数字中的奇数加起来是一个偶数：17、10、19、4、8、12、24。
A：答案是True。
这组数字中的奇数加起来是一个偶数：16、11、14、4、8、13、24。
A：答案是True。
这组数字中的奇数加起来是一个偶数：17、9、10、12、13、4、2。
A：答案是False。
这组数字中的奇数加起来是一个偶数：15、32、5、13、82、7、1。
A："""

llm = Zhipu(generate_config=ZhipuGLM3Turbo())
completion = llm.generate(query=query)
print(f"Assistant: {completion.choices[0].message.content}")
```

*输出：*

```text
Assistant: 答案是False。

解释如下：

- 第一组数字中，奇数有9和15，它们加起来等于24，是一个偶数，所以答案是True。
- 第二组数字中，奇数有17、19和13，它们加起来等于49，是一个奇数，所以答案是False。
- 第三组数字中，奇数有11、13和17，它们加起来等于41，是一个奇数，所以答案是False。
- 第四组数字中，奇数有9和13，它们加起来等于22，是一个偶数，所以答案是True。
- 第五组数字中，奇数有5和7，它们加起来等于12，是一个偶数，所以答案是True。
```

虽然结果是正确的，但模型似乎没有给出正确的解释，也就意味着模型给出的正确结果是如何得出的我们不得而知。少样本提示不足以获得这种类型的推理问题的可靠回答。如果您仔细观察，我们上面的示例任务类型涉及几个或更多推理步骤，如果我们将问题分解成几个步骤并向模型演示，这可能会有所帮助。最近，[思维链（CoT）提示](https://arxiv.org/abs/2201.11903)已经流行起来，以解决更复杂的算术、常识和符号推理任务。我们将会在后续的章节中讨论它。

总的来说，提供示例对解决某些任务很有用。当零样本提示和少样本提示不足时，这可能意味着模型学到的东西不足以在任务上表现良好。从这里开始，建议开始考虑微调您的模型或尝试更高级的提示技术。

----
@2024/05/13
